{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30b8083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save canonical dataset reference\n",
    "reference_data = {\n",
    "    'total_canonical_datasets': 10,\n",
    "    'configurations': dataset_configs,\n",
    "    'metadata': dataset_metadata\n",
    "}\n",
    "\n",
    "with open(output_dir / 'canonical_datasets.json', 'w') as f:\n",
    "    json.dump(reference_data, f, indent=2)\n",
    "\n",
    "print(f\"Canonical dataset reference saved to: {output_dir / 'canonical_datasets.json'}\")\n",
    "print(\"\\nData exploration completed successfully! âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd6b602",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "### Dataset Composition\n",
    "- **10 Total Canonical Datasets**\n",
    "  - 5 Sarcasm Detection datasets with varying multimodal support\n",
    "  - 3 Paraphrasing datasets (text-only)\n",
    "  - 2 Fact Verification datasets (text-based claim-evidence pairs)\n",
    "\n",
    "### Modality Coverage\n",
    "- **Text**: All 10 datasets (100%)\n",
    "- **Image**: 2 datasets (MMSD2, SarcNet)\n",
    "- **Audio**: 1 dataset (MUStARD)\n",
    "- **Video**: 1 dataset (MUStARD)\n",
    "\n",
    "### Size Variation\n",
    "- Small: MUStARD (690 samples)\n",
    "- Medium: LIAR (12.8k), SarcNet (3.3k), MRPC (5.8k)\n",
    "- Large: Headlines (28.6k), MMSD2 (24.6k)\n",
    "- Very Large: Quora (400k), FEVER (185k), ParaNMT (5M capped at 100k), SARC (1.3M capped at 50k)\n",
    "\n",
    "### Research-Grade Capping\n",
    "- ParaNMT-5M: Capped at 100k to prevent task domination\n",
    "- SARC: Capped at 50k for balanced training\n",
    "- All other datasets: Full or standard splits used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b1156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary_data = []\n",
    "for dataset, metadata in sorted(dataset_metadata.items()):\n",
    "    summary_data.append({\n",
    "        'Dataset': dataset,\n",
    "        'Task': metadata['task'],\n",
    "        'Modalities': ', '.join(metadata['modalities']),\n",
    "        'Approx Size': metadata['size']\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\nCanonical Dataset Summary:\")\n",
    "print(\"=\"*100)\n",
    "print(df_summary.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nTotal Datasets: {len(dataset_metadata)}\")\n",
    "print(f\"Sarcasm Detection: 5 datasets\")\n",
    "print(f\"Paraphrasing: 3 datasets\")\n",
    "print(f\"Fact Verification: 2 datasets\")\n",
    "\n",
    "# Modality coverage\n",
    "modality_count = {}\n",
    "for dataset, metadata in dataset_metadata.items():\n",
    "    for mod in metadata['modalities']:\n",
    "        modality_count[mod] = modality_count.get(mod, 0) + 1\n",
    "\n",
    "print(f\"\\nModality Coverage:\")\n",
    "for mod, count in sorted(modality_count.items()):\n",
    "    print(f\"  {mod}: {count} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5d85fb",
   "metadata": {},
   "source": [
    "## Dataset Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cdb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define canonical dataset configurations\n",
    "dataset_configs = {\n",
    "    'sarcasm_detection': {\n",
    "        'datasets': ['sarc', 'mmsd2', 'mustard', 'sarcnet', 'sarcasm_headlines'],\n",
    "        'task_type': 'classification',\n",
    "        'num_classes': 2\n",
    "    },\n",
    "    'paraphrasing': {\n",
    "        'datasets': ['paranmt', 'mrpc', 'quora'],\n",
    "        'task_type': 'generation'\n",
    "    },\n",
    "    'fact_verification': {\n",
    "        'datasets': ['fever', 'liar'],\n",
    "        'task_type': 'classification',\n",
    "        'num_classes': 3\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dataset metadata\n",
    "dataset_metadata = {\n",
    "    'sarc': {'modalities': ['text'], 'size': '1.3M (capped at 50k)', 'task': 'sarcasm_detection'},\n",
    "    'mmsd2': {'modalities': ['text', 'image'], 'size': '24.6k', 'task': 'sarcasm_detection'},\n",
    "    'mustard': {'modalities': ['text', 'audio', 'video'], 'size': '690', 'task': 'sarcasm_detection'},\n",
    "    'sarcnet': {'modalities': ['text', 'image'], 'size': '3.3k', 'task': 'sarcasm_detection'},\n",
    "    'sarcasm_headlines': {'modalities': ['text'], 'size': '28.6k', 'task': 'sarcasm_detection'},\n",
    "    'paranmt': {'modalities': ['text'], 'size': '5M (capped at 100k)', 'task': 'paraphrasing'},\n",
    "    'mrpc': {'modalities': ['text'], 'size': '5.8k', 'task': 'paraphrasing'},\n",
    "    'quora': {'modalities': ['text'], 'size': '400k', 'task': 'paraphrasing'},\n",
    "    'fever': {'modalities': ['text'], 'size': '185k', 'task': 'fact_verification'},\n",
    "    'liar': {'modalities': ['text'], 'size': '12.8k', 'task': 'fact_verification'}\n",
    "}\n",
    "\n",
    "# Display configuration\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CANONICAL DATASET CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "for task, config in dataset_configs.items():\n",
    "    print(f\"\\n{task.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Datasets: {', '.join(config['datasets'])}\")\n",
    "    print(f\"  Task Type: {config['task_type']}\")\n",
    "    if 'num_classes' in config:\n",
    "        print(f\"  Classes: {config['num_classes']}\")\n",
    "\n",
    "total_datasets = sum(len(config['datasets']) for config in dataset_configs.values())\n",
    "print(f\"\\nTotal Canonical Datasets: {total_datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed19e64",
   "metadata": {},
   "source": [
    "## Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb484f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().cwd().parent if Path().cwd().name == 'notebooks' else Path().cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = project_root / 'outputs' / 'notebooks'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06430b1",
   "metadata": {},
   "source": [
    "# FactCheck-MM Data Exploration\n",
    "\n",
    "## Overview\n",
    "Comprehensive exploration of FactCheck-MM datasets including statistics, distributions, and modality analysis.\n",
    "\n",
    "## Canonical Datasets (10 Total)\n",
    "\n",
    "**Sarcasm Detection (5 datasets):**\n",
    "- sarc\n",
    "- mmsd2\n",
    "- mustard\n",
    "- sarcnet\n",
    "- sarcasm_headlines\n",
    "\n",
    "**Paraphrasing (3 datasets):**\n",
    "- paranmt\n",
    "- mrpc\n",
    "- quora\n",
    "\n",
    "**Fact Verification (2 datasets):**\n",
    "- fever\n",
    "- liar"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
