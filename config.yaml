# Model Configuration
models:
  multimodal_sarcasm:
    text_model: "bert-base-uncased"
    hidden_dim: 768
    visual_dim: 2048
    audio_dim: 1024
    dropout: 0.3
    num_classes: 2
    
  paraphrase:
    model: "bert-base-uncased"
    max_length: 512
    dropout: 0.3
    num_classes: 2
    
  fact_verification:
    model: "bert-base-uncased"
    max_length: 512
    dropout: 0.3
    num_classes: 3

# Training Configuration  
training:
  batch_size: 4  # Smaller batches for small dataset
  learning_rate: 0.00005  # Lower learning rate
  num_epochs: 10  # More epochs to learn patterns
  warmup_steps: 50
  weight_decay: 0.0001
  gradient_clip: 1.0
  eval_steps: 5
  save_steps: 50

# Data Paths
data_paths:
  mustard: "data/multimodal/"
  sarc: "data/text/sarc/"
  headlines: "data/text/Sarcasm_Headlines_Dataset.json"
  mrpc: "data/text/paraphrasing/MRPC/"
  quora: "data/text/paraphrasing/quora/"
  paranmt: "data/text/paraphrasing/para-nmt-5m-processed.txt"
  liar: "data/fact_verification/"
  fever: "data/fact_verification/"

# Checkpoint Paths
checkpoints:
  multimodal_sarcasm: "checkpoints/multimodal_sarcasm/"
  paraphrase: "checkpoints/paraphrase/"
  fact_verification: "checkpoints/fact_verification/"

# API Configuration
api:
  host: "0.0.0.0"
  port: 5000
  debug: true
